{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wZ4QQGLg8Aq",
        "outputId": "946d8e6e-f49b-4efb-eb01-c01bd12da1a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.82      0.83        85\n",
            "           1       0.75      0.76      0.75        58\n",
            "\n",
            "    accuracy                           0.80       143\n",
            "   macro avg       0.79      0.79      0.79       143\n",
            "weighted avg       0.80      0.80      0.80       143\n",
            "\n",
            "Accuracy: 0.7972027972027972\n",
            "KNN (k=5)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.81      0.80        85\n",
            "           1       0.71      0.69      0.70        58\n",
            "\n",
            "    accuracy                           0.76       143\n",
            "   macro avg       0.75      0.75      0.75       143\n",
            "weighted avg       0.76      0.76      0.76       143\n",
            "\n",
            "Accuracy: 0.7622377622377622\n",
            "Decision Tree (max_depth=4)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84        85\n",
            "           1       0.77      0.74      0.75        58\n",
            "\n",
            "    accuracy                           0.80       143\n",
            "   macro avg       0.80      0.79      0.80       143\n",
            "weighted avg       0.80      0.80      0.80       143\n",
            "\n",
            "Accuracy: 0.8041958041958042\n"
          ]
        }
      ],
      "source": [
        "# Scenario Question: Predicting Titanic Survival\n",
        "# Researchers are studying the Titanic disaster and want to build models that predict whether a\n",
        "#  passenger would survive or not survive based on their information.\n",
        "# - Features used:\n",
        "# - Passenger class (pclass)\n",
        "# - Gender (sex)\n",
        "# - Age (age)\n",
        "# - Number of siblings/spouses aboard (sibsp)\n",
        "# - Number of parents/children aboard (parch)\n",
        "# - Ticket fare (fare)\n",
        "# - Label:\n",
        "# - 1 = Survived\n",
        "# - 0 = Died\n",
        "# The researchers train three different models:\n",
        "# - Logistic Regression\n",
        "# - K-Nearest Neighbors (KNN) with k=5\n",
        "# - Decision Tree with max depth = 4\n",
        "# They then evaluate each model using a classification report (precision, recall, F1-score, accuracy).\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "df = df[['survived','pclass','sex','age','sibsp','parch','fare']]\n",
        "df = df.dropna()\n",
        "\n",
        "df['sex'] = df['sex'].map({'male':0,'female':1})\n",
        "\n",
        "X = df.drop('survived',axis=1)\n",
        "y = df['survived']\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "log_model = LogisticRegression(max_iter=1000)\n",
        "log_model.fit(X_train_scaled,y_train)\n",
        "log_pred = log_model.predict(X_test_scaled)\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train_scaled,y_train)\n",
        "knn_pred = knn_model.predict(X_test_scaled)\n",
        "\n",
        "tree_model = DecisionTreeClassifier(max_depth=4,random_state=42)\n",
        "tree_model.fit(X_train,y_train)\n",
        "tree_pred = tree_model.predict(X_test)\n",
        "\n",
        "print(\"Logistic Regression\")\n",
        "print(classification_report(y_test,log_pred))\n",
        "print(\"Accuracy:\",accuracy_score(y_test,log_pred))\n",
        "\n",
        "print(\"KNN (k=5)\")\n",
        "print(classification_report(y_test,knn_pred))\n",
        "print(\"Accuracy:\",accuracy_score(y_test,knn_pred))\n",
        "\n",
        "print(\"Decision Tree (max_depth=4)\")\n",
        "print(classification_report(y_test,tree_pred))\n",
        "print(\"Accuracy:\",accuracy_score(y_test,tree_pred))"
      ]
    }
  ]
}